{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c2c3ff6-1f8b-4eef-85ec-03d6b31c6d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Cases: 100%|████████████████████████| 3/3 [00:02<00:00,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved to Parsed_Criminal_Case_Samples.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "def scrape_criminal_case(case_number):\n",
    "    url = f'https://jpwebsite.harriscountytx.gov/CaseInfo/GetCaseInfo?case={case_number}'\n",
    "    try:\n",
    "        response = requests.get(url, timeout=10)\n",
    "        response.raise_for_status()\n",
    "    except requests.RequestException as e:\n",
    "        return {'Case Number': case_number, 'Error': str(e)}\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    result = {'Case Number': case_number}\n",
    "\n",
    "    # --- Core Info Fields ---\n",
    "    label_map = {\n",
    "        'Style of Case:': 'Style of Case',\n",
    "        'Citation Number:': 'Citation Number',\n",
    "        'Offense Date:': 'Offense Date',\n",
    "        'Arresting Agency:': 'Arresting Agency',\n",
    "        'Arresting Officer:': 'Arresting Officer',\n",
    "        'Offense Charged:': 'Offense Charged',\n",
    "        'Plea Entered:': 'Plea Entered',\n",
    "        'Plea Date:': 'Plea Date',\n",
    "        'Filed Date:': 'Filed Date',\n",
    "        'Case Status:': 'Case Status',\n",
    "        'Disposition:': 'Disposition',\n",
    "        'Disposition Date:': 'Disposition Date',\n",
    "        'Judgment Date:': 'Judgment Date',\n",
    "    }\n",
    "\n",
    "    spans = soup.find_all(\"span\")\n",
    "    for i in range(len(spans) - 1):\n",
    "        label = spans[i].text.strip()\n",
    "        value = spans[i + 1].text.strip()\n",
    "        if label in label_map:\n",
    "            result[label_map[label]] = value\n",
    "        elif label == \"Party Type:\" and value == \"Defendant\":\n",
    "            result[\"Defendant\"] = spans[i - 1].text.strip()\n",
    "        elif label == \"Party Type:\" and value == \"Officer\":\n",
    "            result[\"Officer\"] = spans[i - 1].text.strip()\n",
    "\n",
    "    # --- Hearings (up to 10) ---\n",
    "    hearing_count = 0\n",
    "    for i in range(len(spans) - 1):\n",
    "        label = spans[i].text.strip()\n",
    "        if label == \"Hearing Description:\" and hearing_count < 10:\n",
    "            desc = spans[i + 1].text.strip()\n",
    "            date = outcome = ''\n",
    "            if i + 3 < len(spans) and spans[i + 2].text.strip() == \"Hearing Date/Time:\":\n",
    "                date = spans[i + 3].text.strip()\n",
    "            if i + 5 < len(spans) and spans[i + 4].text.strip() == \"Hearing Result/Cancellation:\":\n",
    "                outcome = spans[i + 5].text.strip()\n",
    "\n",
    "            result[f'Hearing Description {hearing_count+1}'] = desc\n",
    "            result[f'Hearing Date/Time {hearing_count+1}'] = date\n",
    "            result[f'Hearing Result/Cancellation {hearing_count+1}'] = outcome\n",
    "            hearing_count += 1\n",
    "\n",
    "    for i in range(hearing_count + 1, 11):\n",
    "        result[f'Hearing Description {i}'] = ''\n",
    "        result[f'Hearing Date/Time {i}'] = ''\n",
    "        result[f'Hearing Result/Cancellation {i}'] = ''\n",
    "\n",
    "    # --- Events (up to 20) ---\n",
    "    event_count = 0\n",
    "    for i in range(len(spans) - 1):\n",
    "        label = spans[i].text.strip().replace('\\xa0', '').replace('\\t', '')\n",
    "        if label.startswith(\"Event Description\") and event_count < 20:\n",
    "            desc = spans[i + 1].text.strip()\n",
    "            date = ''\n",
    "            if i + 3 < len(spans) and spans[i + 2].text.strip().startswith(\"Date Added\"):\n",
    "                date = spans[i + 3].text.strip()\n",
    "\n",
    "            result[f'Event Description {event_count+1}'] = desc\n",
    "            result[f'Event Date Added {event_count+1}'] = date\n",
    "            event_count += 1\n",
    "\n",
    "    for i in range(event_count + 1, 21):\n",
    "        result[f'Event Description {i}'] = ''\n",
    "        result[f'Event Date Added {i}'] = ''\n",
    "\n",
    "    return result\n",
    "\n",
    "# --- List of 3 Sample Cases ---\n",
    "sample_case_numbers = ['232200082938', '231200095502', '191100196678']\n",
    "\n",
    "# --- Scrape All with Progress Bar ---\n",
    "results = []\n",
    "for case in tqdm(sample_case_numbers, desc=\"Scraping Cases\"):\n",
    "    results.append(scrape_criminal_case(case))\n",
    "    time.sleep(0.5)  # Rate limit to avoid overwhelming the site\n",
    "\n",
    "# --- Save to CSV ---\n",
    "df = pd.DataFrame(results)\n",
    "df.to_csv('Parsed_Criminal_Case_Samples.csv', index=False)\n",
    "print(\"✅ Saved to Parsed_Criminal_Case_Samples.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5505a3d6-f3a0-4ce8-937c-17ce7e9caee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Random 10 Cases: 100%|████████████| 10/10 [00:10<00:00,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved to Criminal_Case_Sample_10.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "def scrape_criminal_case(case_number):\n",
    "    url = f'https://jpwebsite.harriscountytx.gov/CaseInfo/GetCaseInfo?case={case_number}'\n",
    "    try:\n",
    "        response = requests.get(url, timeout=10)\n",
    "        response.raise_for_status()\n",
    "    except requests.RequestException as e:\n",
    "        return {'Case Number': case_number, 'Error': str(e)}\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    result = {'Case Number': case_number}\n",
    "\n",
    "    label_map = {\n",
    "        'Style of Case:': 'Style of Case',\n",
    "        'Citation Number:': 'Citation Number',\n",
    "        'Offense Date:': 'Offense Date',\n",
    "        'Arresting Agency:': 'Arresting Agency',\n",
    "        'Arresting Officer:': 'Arresting Officer',\n",
    "        'Offense Charged:': 'Offense Charged',\n",
    "        'Plea Entered:': 'Plea Entered',\n",
    "        'Plea Date:': 'Plea Date',\n",
    "        'Filed Date:': 'Filed Date',\n",
    "        'Case Status:': 'Case Status',\n",
    "        'Disposition:': 'Disposition',\n",
    "        'Disposition Date:': 'Disposition Date',\n",
    "        'Judgment Date:': 'Judgment Date',\n",
    "    }\n",
    "\n",
    "    spans = soup.find_all(\"span\")\n",
    "    for i in range(len(spans) - 1):\n",
    "        label = spans[i].text.strip()\n",
    "        value = spans[i + 1].text.strip()\n",
    "        if label in label_map:\n",
    "            result[label_map[label]] = value\n",
    "        elif label == \"Party Type:\" and value == \"Defendant\":\n",
    "            result[\"Defendant\"] = spans[i - 1].text.strip()\n",
    "        elif label == \"Party Type:\" and value == \"Officer\":\n",
    "            result[\"Officer\"] = spans[i - 1].text.strip()\n",
    "\n",
    "    hearing_count = 0\n",
    "    for i in range(len(spans) - 1):\n",
    "        label = spans[i].text.strip()\n",
    "        if label == \"Hearing Description:\" and hearing_count < 10:\n",
    "            desc = spans[i + 1].text.strip()\n",
    "            date = outcome = ''\n",
    "            if i + 3 < len(spans) and spans[i + 2].text.strip() == \"Hearing Date/Time:\":\n",
    "                date = spans[i + 3].text.strip()\n",
    "            if i + 5 < len(spans) and spans[i + 4].text.strip() == \"Hearing Result/Cancellation:\":\n",
    "                outcome = spans[i + 5].text.strip()\n",
    "\n",
    "            result[f'Hearing Description {hearing_count+1}'] = desc\n",
    "            result[f'Hearing Date/Time {hearing_count+1}'] = date\n",
    "            result[f'Hearing Result/Cancellation {hearing_count+1}'] = outcome\n",
    "            hearing_count += 1\n",
    "\n",
    "    for i in range(hearing_count + 1, 11):\n",
    "        result[f'Hearing Description {i}'] = ''\n",
    "        result[f'Hearing Date/Time {i}'] = ''\n",
    "        result[f'Hearing Result/Cancellation {i}'] = ''\n",
    "\n",
    "    event_count = 0\n",
    "    for i in range(len(spans) - 1):\n",
    "        label = spans[i].text.strip().replace('\\xa0', '').replace('\\t', '')\n",
    "        if label.startswith(\"Event Description\") and event_count < 20:\n",
    "            desc = spans[i + 1].text.strip()\n",
    "            date = ''\n",
    "            if i + 3 < len(spans) and spans[i + 2].text.strip().startswith(\"Date Added\"):\n",
    "                date = spans[i + 3].text.strip()\n",
    "\n",
    "            result[f'Event Description {event_count+1}'] = desc\n",
    "            result[f'Event Date Added {event_count+1}'] = date\n",
    "            event_count += 1\n",
    "\n",
    "    for i in range(event_count + 1, 21):\n",
    "        result[f'Event Description {i}'] = ''\n",
    "        result[f'Event Date Added {i}'] = ''\n",
    "\n",
    "    return result\n",
    "\n",
    "# --- Load your dataset and get 10 unique case numbers with JP Court ID ---\n",
    "df = pd.read_csv('Harris_CrimCITHearings_2021Apr2025_CLEAN.csv', low_memory=False)\n",
    "df_sample = df[['Case Number', 'JP Court ID']].dropna().drop_duplicates()\n",
    "sampled_cases = df_sample.sample(n=10, random_state=42)\n",
    "\n",
    "# --- Scrape each and add JP Court ID ---\n",
    "results = []\n",
    "for _, row in tqdm(sampled_cases.iterrows(), total=10, desc=\"Scraping Random 10 Cases\"):\n",
    "    case_number = str(row['Case Number']).strip()\n",
    "    court_id = row['JP Court ID']\n",
    "    result = scrape_criminal_case(case_number)\n",
    "    result['JP Court ID'] = court_id\n",
    "    results.append(result)\n",
    "    time.sleep(0.5)\n",
    "\n",
    "# --- Export results ---\n",
    "pd.DataFrame(results).to_csv('Criminal_Case_Sample_10.csv', index=False)\n",
    "print(\"✅ Saved to Criminal_Case_Sample_10.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4441b171-2ad2-4c68-9d39-4535b1dc3450",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ferna\\AppData\\Local\\Temp\\ipykernel_22068\\3498655987.py:93: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  final_sample = df_filtered.groupby('JP Court ID').apply(\n",
      "Scraping All Courts: 100%|█████████████████████████████████████████████████████████████| 16/16 [00:13<00:00,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Done! Saved to Criminal_Case_Full_Sample.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# -------- Scraper Function -------- #\n",
    "def scrape_criminal_case(case_number):\n",
    "    url = f'https://jpwebsite.harriscountytx.gov/CaseInfo/GetCaseInfo?case={case_number}'\n",
    "    try:\n",
    "        response = requests.get(url, timeout=10)\n",
    "        response.raise_for_status()\n",
    "    except requests.RequestException as e:\n",
    "        return {'Case Number': case_number, 'Error': str(e)}\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    result = {'Case Number': case_number}\n",
    "\n",
    "    label_map = {\n",
    "        'Style of Case:': 'Style of Case',\n",
    "        'Citation Number:': 'Citation Number',\n",
    "        'Offense Date:': 'Offense Date',\n",
    "        'Arresting Agency:': 'Arresting Agency',\n",
    "        'Arresting Officer:': 'Arresting Officer',\n",
    "        'Offense Charged:': 'Offense Charged',\n",
    "        'Plea Entered:': 'Plea Entered',\n",
    "        'Plea Date:': 'Plea Date',\n",
    "        'Filed Date:': 'Filed Date',\n",
    "        'Case Status:': 'Case Status',\n",
    "        'Disposition:': 'Disposition',\n",
    "        'Disposition Date:': 'Disposition Date',\n",
    "        'Judgment Date:': 'Judgment Date',\n",
    "    }\n",
    "\n",
    "    spans = soup.find_all(\"span\")\n",
    "    for i in range(len(spans) - 1):\n",
    "        label = spans[i].text.strip()\n",
    "        value = spans[i + 1].text.strip()\n",
    "        if label in label_map:\n",
    "            result[label_map[label]] = value\n",
    "        elif label == \"Party Type:\" and value == \"Defendant\":\n",
    "            result[\"Defendant\"] = spans[i - 1].text.strip()\n",
    "        elif label == \"Party Type:\" and value == \"Officer\":\n",
    "            result[\"Officer\"] = spans[i - 1].text.strip()\n",
    "\n",
    "    hearing_count = 0\n",
    "    for i in range(len(spans) - 1):\n",
    "        label = spans[i].text.strip()\n",
    "        if label == \"Hearing Description:\" and hearing_count < 10:\n",
    "            desc = spans[i + 1].text.strip()\n",
    "            date = outcome = ''\n",
    "            if i + 3 < len(spans) and spans[i + 2].text.strip() == \"Hearing Date/Time:\":\n",
    "                date = spans[i + 3].text.strip()\n",
    "            if i + 5 < len(spans) and spans[i + 4].text.strip() == \"Hearing Result/Cancellation:\":\n",
    "                outcome = spans[i + 5].text.strip()\n",
    "\n",
    "            result[f'Hearing Description {hearing_count+1}'] = desc\n",
    "            result[f'Hearing Date/Time {hearing_count+1}'] = date\n",
    "            result[f'Hearing Result/Cancellation {hearing_count+1}'] = outcome\n",
    "            hearing_count += 1\n",
    "\n",
    "    for i in range(hearing_count + 1, 11):\n",
    "        result[f'Hearing Description {i}'] = ''\n",
    "        result[f'Hearing Date/Time {i}'] = ''\n",
    "        result[f'Hearing Result/Cancellation {i}'] = ''\n",
    "\n",
    "    event_count = 0\n",
    "    for i in range(len(spans) - 1):\n",
    "        label = spans[i].text.strip().replace('\\xa0', '').replace('\\t', '')\n",
    "        if label.startswith(\"Event Description\") and event_count < 20:\n",
    "            desc = spans[i + 1].text.strip()\n",
    "            date = ''\n",
    "            if i + 3 < len(spans) and spans[i + 2].text.strip().startswith(\"Date Added\"):\n",
    "                date = spans[i + 3].text.strip()\n",
    "\n",
    "            result[f'Event Description {event_count+1}'] = desc\n",
    "            result[f'Event Date Added {event_count+1}'] = date\n",
    "            event_count += 1\n",
    "\n",
    "    for i in range(event_count + 1, 21):\n",
    "        result[f'Event Description {i}'] = ''\n",
    "        result[f'Event Date Added {i}'] = ''\n",
    "\n",
    "    return result\n",
    "\n",
    "# -------- Load & Filter Dataset -------- #\n",
    "df = pd.read_csv('Harris_CrimCITHearings_2021Apr2025_CLEAN.csv', low_memory=False)\n",
    "df['Filed Date'] = pd.to_datetime(df['Filed Date'], errors='coerce')\n",
    "df_filtered = df[df['Filed Date'].dt.year.isin([2023, 2024, 2025])]\n",
    "df_filtered = df_filtered[['Case Number', 'JP Court ID']].dropna().drop_duplicates()\n",
    "\n",
    "# -------- Sample up to 10,000 per JP Court ID -------- #\n",
    "final_sample = df_filtered.groupby('JP Court ID').apply(\n",
    "    lambda g: g.sample(n=min(1, len(g)), random_state=42)\n",
    ").reset_index(drop=True)\n",
    "\n",
    "# -------- Scrape and Track Progress -------- #\n",
    "results = []\n",
    "for idx, row in tqdm(final_sample.iterrows(), total=len(final_sample), desc=\"Scraping All Courts\"):\n",
    "    case_number = str(row['Case Number']).strip()\n",
    "    court_id = row['JP Court ID']\n",
    "    data = scrape_criminal_case(case_number)\n",
    "    data['JP Court ID'] = court_id\n",
    "    results.append(data)\n",
    "    time.sleep(0.5)  # polite delay\n",
    "\n",
    "# -------- Save Output -------- #\n",
    "pd.DataFrame(results).to_csv('Criminal_Case_Full_Sample.csv', index=False)\n",
    "print(\"✅ Done! Saved to Criminal_Case_Full_Sample.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13dcede0-2792-49f6-9eff-3ce8d5eeac3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ferna\\AppData\\Local\\Temp\\ipykernel_7208\\708220088.py:92: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  final_sample = df_filtered.groupby('JP Court ID').apply(\n",
      "Scraping All Courts: 100%|███████████████████████████████████████████████████████████| 180/180 [02:26<00:00,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# -------- Scraper Function -------- #\n",
    "def scrape_criminal_case(case_number):\n",
    "    url = f'https://jpwebsite.harriscountytx.gov/CaseInfo/GetCaseInfo?case={case_number}'\n",
    "    try:\n",
    "        response = requests.get(url, timeout=10)\n",
    "        response.raise_for_status()\n",
    "    except requests.RequestException as e:\n",
    "        return {'Case Number': case_number, 'Error': str(e)}\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    result = {'Case Number': case_number}\n",
    "\n",
    "    label_map = {\n",
    "        'Style of Case:': 'Style of Case',\n",
    "        'Citation Number:': 'Citation Number',\n",
    "        'Offense Date:': 'Offense Date',\n",
    "        'Arresting Agency:': 'Arresting Agency',\n",
    "        'Arresting Officer:': 'Arresting Officer',\n",
    "        'Offense Charged:': 'Offense Charged',\n",
    "        'Plea Entered:': 'Plea Entered',\n",
    "        'Plea Date:': 'Plea Date',\n",
    "        'Filed Date:': 'Filed Date',\n",
    "        'Case Status:': 'Case Status',\n",
    "        'Disposition:': 'Disposition',\n",
    "        'Disposition Date:': 'Disposition Date',\n",
    "        'Judgment Date:': 'Judgment Date',\n",
    "    }\n",
    "\n",
    "    spans = soup.find_all(\"span\")\n",
    "    for i in range(len(spans) - 1):\n",
    "        label = spans[i].text.strip()\n",
    "        value = spans[i + 1].text.strip()\n",
    "        if label in label_map:\n",
    "            result[label_map[label]] = value\n",
    "        elif label == \"Party Type:\" and value == \"Defendant\":\n",
    "            result[\"Defendant\"] = spans[i - 1].text.strip()\n",
    "        elif label == \"Party Type:\" and value == \"Officer\":\n",
    "            result[\"Officer\"] = spans[i - 1].text.strip()\n",
    "\n",
    "    hearing_count = 0\n",
    "    for i in range(len(spans) - 1):\n",
    "        label = spans[i].text.strip()\n",
    "        if label == \"Hearing Description:\" and hearing_count < 10:\n",
    "            desc = spans[i + 1].text.strip()\n",
    "            date = outcome = ''\n",
    "            if i + 3 < len(spans) and spans[i + 2].text.strip() == \"Hearing Date/Time:\":\n",
    "                date = spans[i + 3].text.strip()\n",
    "            if i + 5 < len(spans) and spans[i + 4].text.strip() == \"Hearing Result/Cancellation:\":\n",
    "                outcome = spans[i + 5].text.strip()\n",
    "\n",
    "            result[f'Hearing Description {hearing_count+1}'] = desc\n",
    "            result[f'Hearing Date/Time {hearing_count+1}'] = date\n",
    "            result[f'Hearing Result/Cancellation {hearing_count+1}'] = outcome\n",
    "            hearing_count += 1\n",
    "\n",
    "    for i in range(hearing_count + 1, 11):\n",
    "        result[f'Hearing Description {i}'] = ''\n",
    "        result[f'Hearing Date/Time {i}'] = ''\n",
    "        result[f'Hearing Result/Cancellation {i}'] = ''\n",
    "\n",
    "    event_count = 0\n",
    "    for i in range(len(spans) - 1):\n",
    "        label = spans[i].text.strip().replace('\\xa0', '').replace('\\t', '')\n",
    "        if label.startswith(\"Event Description\") and event_count < 20:\n",
    "            desc = spans[i + 1].text.strip()\n",
    "            date = ''\n",
    "            if i + 3 < len(spans) and spans[i + 2].text.strip().startswith(\"Date Added\"):\n",
    "                date = spans[i + 3].text.strip()\n",
    "\n",
    "            result[f'Event Description {event_count+1}'] = desc\n",
    "            result[f'Event Date Added {event_count+1}'] = date\n",
    "            event_count += 1\n",
    "\n",
    "    for i in range(event_count + 1, 21):\n",
    "        result[f'Event Description {i}'] = ''\n",
    "        result[f'Event Date Added {i}'] = ''\n",
    "\n",
    "    return result\n",
    "\n",
    "# -------- Load & Filter Dataset -------- #\n",
    "df = pd.read_csv('UnresolvedCases_Over10Years_JP12.csv', low_memory=False)\n",
    "df['Case File Date'] = pd.to_datetime(df['Case File Date'], errors='coerce')\n",
    "df_filtered = df[['Case Number', 'JP Court ID']].dropna().drop_duplicates()\n",
    "\n",
    "# -------- Sample up to 10,000 per JP Court ID -------- #\n",
    "final_sample = df_filtered.groupby('JP Court ID').apply(\n",
    "    lambda g: g.sample(n=min(10000, len(g)), random_state=42)\n",
    ").reset_index(drop=True)\n",
    "\n",
    "# -------- Scrape and Track Progress -------- #\n",
    "results = []\n",
    "for idx, row in tqdm(final_sample.iterrows(), total=len(final_sample), desc=\"Scraping All Courts\"):\n",
    "    case_number = str(row['Case Number']).strip()\n",
    "    court_id = row['JP Court ID']\n",
    "    data = scrape_criminal_case(case_number)\n",
    "    data['JP Court ID'] = court_id\n",
    "    results.append(data)\n",
    "    time.sleep(0.5)  # polite delay\n",
    "\n",
    "# -------- Save Output -------- #\n",
    "pd.DataFrame(results).to_csv('UnresolvedCases_Over10Years_JP12_Scraped.csv', index=False)\n",
    "print(\"✅ Done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c784e6ef-fb90-4fd8-97ee-7edf03183bc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
